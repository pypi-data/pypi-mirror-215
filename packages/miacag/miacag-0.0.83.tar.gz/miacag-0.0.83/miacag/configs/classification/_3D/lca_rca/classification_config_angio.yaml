# inputs:

tensorboard_comment: 'test_v1'
DataSetPath: "/home/gandalf/miacag/data/angio"
query: "SELECT * FROM ?schema_name.?table_name WHERE phase IS DISTINCT FROM 'test';"
query_test: "SELECT * FROM ?schema_name.?table_name;"
query_train_plot: "SELECT * FROM ?schema_name.?table_name WHERE (phase = 'train');"
query_val_plot: "SELECT * FROM ?schema_name.?table_name WHERE (phase = 'val');"
query_test_plot: "SELECT * FROM ?schema_name.?table_name WHERE (phase = 'test');"
query_pred: "SELECT * FROM ?schema_name.?table_name;"


table_name: "dicom_table2x"
schema_name: "cag"
TestSize: 0.2


# postgres configs
username: 'gandalf'
password: '123qweasd'
database: 'mydb'
host: "localhost"
# outputs
output: "/home/gandalf/angiography_data/runs/testing_"
# use a fixed random seed to guarantee that when you run the code twice you will get the same outcome
manual_seed: 0

# model configuration
model:
# model class, e.g. UNet
  dimension: 2D+T
  encoder_depth: 4
  in_channels: 1
  backbone: "debug_3d" # "mvit_base_16x4" #"slowfast8x8" #r2plus1_18 #r2plus1_18 #x3d_s #x3d_l #r2plus1_18 # x3d_l
  num_classes: 3
  pretrained: "None" #"/home/sauroman/mia/models/torchhub/3D/mvit_base_16x4" #/home/sauroman/mia/models/torchhub/3D/r2plus1_18 #"/home/sauroman/mia/models/torchhub/3D/mvit_base_16x4"
  pretrain_model: "None"
  pretrain_encoder: "None"
# Data loader configuration
task_type: "classification"
labels_names: ["labels"]
weighted_sampler: "True"
labels_dict: {0: 0,
          1: 1,
          2: 1,
          3: 2,
          4: 2,
          5: 1,
          6: 0,
          7: 1,
          8: 0,
          9: 1,
          10: 2,
          11: 0,
          12: 1,
          13: 0,
          14: 2,
          15: 15,
          16: 16,
          17: 17,
          18: 18,
          19: 19,
          20: 20}
# labels_dict: {0: 0,
#           1: 1,
#           2: 2,
#           3: 3,
#           4: 4,
#           5: 5,
#           6: 6,
#           7: 7,
#           8: 8,
#           9: 9,
#           10: 10,
#           11: 11,
#           12: 12,
#           13: 13,
#           14: 14,
#           15: 15,
#           16: 16,
#           17: 17,
#           18: 18,
#           19: 19,
#           20: 20}
cache_num: 3
cache_test: "False"
'replace_rate': 1 #0.25
loaders:
  #dimension order
  format: 'dicom'
  store_memory: False

  use_amp: False
  

  CropForeGround: False
  isCT: False

  spatial_resize: False

  pixdim_height: 4 # 0.213828125
  pixdim_width: 4 # 0.213828125
  pixdim_depth: 66 # 0.33 # 1/66.673
  Resize_height: 130 #130 #312 #130 #130 # 130
  Resize_width: 130 #130 #312 #130 #130 # 130
  Resize_depth: -1 #-1

  spatial_scaling: "False"
  temporal_scaling: "False"
  translate: "False"
  rotate: "False"

  Crop_height: 130 #130 #312 #130 #130 # 130
  Crop_width: 130 #130 #312 #224 #224 # 224
  Crop_depth: 16
  batchSize: 1


  # validation method 
  val_method:
    type: patches #'sliding_window' # patches | sliding_window
    samples: 1
    saliency: 'False'
    misprediction: 'False'

# trainer configuration
trainer:
  # how many iterations between validations
  validate_frequency: 2
  # max number of epochs
  epochs: 50
  # number of epochs before use early stopping
  max_stagnation: 100

# optimizer configuration
optimizer:
  type: "sgd" # 
  # initial learning rate
  learning_rate: 0.10 # 0.0003125 # 0.05*BS/256 -> 0.1 if BS=512
  # weight decay
  weight_decay: 0.0005 #5e-4 
  momentum: 0.9

lr_scheduler:
  type: None #
  lr_warmup_epochs: 10
  steps_for_drop: 1
  gamma: 0.2
# loss function configuration
loss:
  # loss function to be used during training
  name: ['CE'] #CE_pixel CE_pixel
# evaluation metric configuration
eval_metric_train:
  name: ['acc_top_1']
eval_metric_val:
  name: ['acc_top_1']
# learning rate scheduler configuration

