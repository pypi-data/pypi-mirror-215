"""Protein loader class inherited from `torch.utils.data.DataLoader`."""

import random

import numpy as np
import torch
from torch.utils.data import DataLoader

from proteinflow.constants import CDR
from proteinflow.protein_dataset import ProteinDataset


class _PadCollate:
    """A variant of `collate_fn` that pads according to the longest sequence in a batch of sequences.

    If `mask_residues` is `True`, an additional `'masked_res'` key is added to the output. The value is a binary
    tensor where 1 denotes the part that needs to be predicted and 0 is everything else. The tensors are generated
    according to the following rules:
    - if `mask_whole_chains` is `True`, the whole chain is masked
    - if `mask_frac` is given, the number of residues to mask is `mask_frac` times the length of the chain,
    - otherwise, the number of residues to mask is sampled uniformly from the range [`lower_limit`, `upper_limit`].

    If `force_binding_sites_frac` > 0 and `mask_whole_chains` is `False`, in the fraction of cases where a chain
    from a polymer is sampled, the center of the masked region will be forced to be in a binding site.

    """

    def __init__(
        self,
        mask_residues=True,
        lower_limit=15,
        upper_limit=100,
        mask_frac=None,
        mask_whole_chains=False,
        force_binding_sites_frac=0.15,
        mask_all_cdrs=False,
    ):
        """Initialize a _PadCollate object.

        Parameters
        ----------
        batch : dict
            a batch generated by `ProteinDataset` and `PadCollate`
        lower_limit : int, default 15
            the minimum number of residues to mask
        upper_limit : int, default 100
            the maximum number of residues to mask
        mask_frac : float, optional
            if given, the `lower_limit` and `upper_limit` are ignored and the number of residues to mask is `mask_frac` times the length of the chain
        mask_whole_chains : bool, default False
            if `True`, `upper_limit`, `force_binding_sites` and `lower_limit` are ignored and the whole chain is masked instead
        force_binding_sites_frac : float, default 0.15
            if > 0, in the fraction of cases where a chain from a polymer is sampled, the center of the masked region will be
            forced to be in a binding site
        mask_all_cdrs : bool, default False
            if `True`, all CDRs are masked

        Returns
        -------
        chain_M : torch.Tensor
            a `(B, L)` shaped binary tensor where 1 denotes the part that needs to be predicted and
            0 is everything else

        """
        super().__init__()
        self.mask_residues = mask_residues
        self.lower_limit = lower_limit
        self.upper_limit = upper_limit
        self.mask_frac = mask_frac
        self.mask_whole_chains = mask_whole_chains
        self.force_binding_sites_frac = force_binding_sites_frac
        self.mask_all_cdrs = mask_all_cdrs

    def _get_masked_sequence(
        self,
        batch,
    ):
        """Get the mask for the residues that need to be predicted.

        Depending on the parameters the residues are selected as follows:
        - if `mask_whole_chains` is `True`, the whole chain is masked
        - if `mask_frac` is given, the number of residues to mask is `mask_frac` times the length of the chain,
        - otherwise, the number of residues to mask is sampled uniformly from the range [`lower_limit`, `upper_limit`].

        If `force_binding_sites_frac` > 0 and `mask_whole_chains` is `False`, in the fraction of cases where a chain
        from a polymer is sampled, the center of the masked region will be forced to be in a binding site.

        Parameters
        ----------
        batch : dict
            a batch generated by `ProteinDataset` and `PadCollate`

        Returns
        -------
        chain_M : torch.Tensor
            a `(B, L)` shaped binary tensor where 1 denotes the part that needs to be predicted and
            0 is everything else

        """
        if "cdr" in batch and "cdr_id" in batch:
            chain_M = torch.zeros_like(batch["cdr"])
            for i, cdr_arr in enumerate(batch["cdr"]):
                if self.mask_all_cdrs:
                    chain_M[i] = cdr_arr != CDR["-"]
                else:
                    chain_M[i] = cdr_arr == batch["cdr_id"][i]
        else:
            chain_M = torch.zeros(batch["S"].shape)
            for i, coords in enumerate(batch["X"]):
                chain_index = batch["chain_id"][i]
                chain_bool = batch["chain_encoding_all"][i] == chain_index

                if self.mask_whole_chains:
                    chain_M[i, chain_bool] = 1
                else:
                    chains = torch.unique(batch["chain_encoding_all"][i])
                    chain_start = torch.where(chain_bool)[0][0]
                    chain = coords[chain_bool]
                    res_i = None
                    interface = []
                    non_masked_interface = []
                    if len(chains) > 1 and self.force_binding_sites_frac > 0:
                        if random.uniform(0, 1) <= self.force_binding_sites_frac:
                            X_copy = coords

                            i_indices = (chain_bool == 0).nonzero().flatten()
                            j_indices = chain_bool.nonzero().flatten()

                            distances = torch.norm(
                                X_copy[i_indices, 2, :]
                                - X_copy[j_indices, 2, :].unsqueeze(1),
                                dim=-1,
                            ).cpu()
                            close_idx = (
                                np.where(torch.min(distances, dim=1)[0] <= 10)[0]
                                + chain_start.item()
                            )

                            no_mask_idx = np.where(batch["mask"][i][chain_bool])[0]
                            interface = np.intersect1d(close_idx, j_indices)

                            not_end_mask = np.where(
                                (X_copy[:, 2, :].cpu() == 0).sum(-1) != 3
                            )[0]
                            interface = np.intersect1d(interface, not_end_mask)

                            non_masked_interface = np.intersect1d(
                                interface, no_mask_idx
                            )
                            interpolate = True
                            if len(non_masked_interface) > 0:
                                res_i = non_masked_interface[
                                    random.randint(0, len(non_masked_interface) - 1)
                                ]
                            elif len(interface) > 0 and interpolate:
                                res_i = interface[random.randint(0, len(interface) - 1)]
                            else:
                                res_i = no_mask_idx[
                                    random.randint(0, len(no_mask_idx) - 1)
                                ]
                    if res_i is None:
                        non_zero = torch.where(batch["mask"][i][chain_bool])[0]
                        res_i = non_zero[random.randint(0, len(non_zero) - 1)]
                    res_coords = coords[res_i, 2, :]
                    neighbor_indices = torch.where(batch["mask"][i][chain_bool])[0]
                    if self.mask_frac is not None:
                        assert self.mask_frac > 0 and self.mask_frac < 1
                        k = int(len(neighbor_indices) * self.mask_frac)
                        k = max(k, 10)
                    else:
                        up = min(
                            self.upper_limit, int(len(neighbor_indices) * 0.5)
                        )  # do not mask more than half of the sequence
                        low = min(up - 1, self.lower_limit)
                        k = random.choice(range(low, up))
                    dist = torch.norm(
                        chain[neighbor_indices, 2, :] - res_coords.unsqueeze(0), dim=-1
                    )
                    closest_indices = neighbor_indices[
                        torch.topk(dist, k, largest=False)[1]
                    ]
                    chain_M[i, closest_indices + chain_start] = 1
        return chain_M

    def pad_collate(self, batch):
        # find longest sequence
        out = {}
        max_len = max(map(lambda x: x["S"].shape[0], batch))

        # pad according to max_len
        to_pad = [max_len - b["S"].shape[0] for b in batch]
        for key in batch[0].keys():
            if key in ["chain_id", "chain_dict", "pdb_id", "cdr_id"]:
                continue
            out[key] = torch.stack(
                [
                    torch.cat([b[key], torch.zeros((pad, *b[key].shape[1:]))], 0)
                    for b, pad in zip(batch, to_pad)
                ],
                0,
            )
        out["chain_id"] = torch.tensor([b["chain_id"] for b in batch])
        if "cdr_id" in batch[0]:
            out["cdr_id"] = torch.tensor([b["cdr_id"] for b in batch])
        out["masked_res"] = self._get_masked_sequence(out)
        out["chain_dict"] = [b["chain_dict"] for b in batch]
        out["pdb_id"] = [b["pdb_id"] for b in batch]
        return out

    def __call__(self, batch):
        return self.pad_collate(batch)


class ProteinLoader(DataLoader):
    """A subclass of `torch.data.utils.DataLoader` tuned for the `proteinflow` dataset.

    Creates and iterates over an instance of `ProteinDataset`, omitting the `'chain_dict'` keys.
    See the `ProteinDataset` documentation for more information.

    If batch size is larger than one, all objects are padded with zeros at the ends to reach the length of the
    longest protein in the batch.

    If `mask_residues` is `True`, an additional `'masked_res'` key is added to the output. The value is a binary
    tensor shaped `(B, L)` where 1 denotes the part that needs to be predicted and 0 is everything else. The tensors are generated
    according to the following rulesd:
    - if the dataset is generated from SAbDab files, the sampled CDR is masked,
    - if `mask_whole_chains` is `True`, the whole chain is masked,
    - if `mask_frac` is given, the number of residues to mask is `mask_frac` times the length of the chain,
    - otherwise, the number of residues to mask is sampled uniformly from the range [`lower_limit`, `upper_limit`].

    If `force_binding_sites_frac` > 0 and `mask_whole_chains` is `False`, in the fraction of cases where a chain
    from a polymer is sampled, the center of the masked region will be forced to be in a binding site (in PDB datasets).
    """

    def __init__(
        self,
        dataset,
        lower_limit=15,
        upper_limit=100,
        mask_residues=True,
        mask_whole_chains=False,
        mask_frac=None,
        collate_func=_PadCollate,
        force_binding_sites_frac=0,
        shuffle_batches=True,
        mask_all_cdrs=False,
        *args,
        **kwargs,
    ):
        """Initialize a ProteinLoader instance.

        Parameters
        ----------
        dataset : ProteinDataset
            a ProteinDataset instance
        lower_limit : int, default 15
            the minimum number of residues to mask
        upper_limit : int, default 100
            the maximum number of residues to mask
        mask_frac : float, optional
            if given, the `lower_limit` and `upper_limit` are ignored and the number of residues to mask is `mask_frac` times the length of the chain
        mask_whole_chains : bool, default False
            if `True`, `upper_limit`, `force_binding_sites` and `lower_limit` are ignored and the whole chain is masked instead
        force_binding_sites_frac : float, default 0
            if > 0, in the fraction of cases where a chain from a polymer is sampled, the center of the masked region will be
            forced to be in a binding site
        shuffle_clusters : bool, default True
            if `True`, a new representative is randomly selected for each cluster at each epoch (if `clustering_dict_path` is given)
        shuffle_batches : bool, default True
            if `True`, the batches are shuffled at each epoch
        mask_all_cdrs : bool, default False
            if `True`, all CDRs are masked instead of just the sampled one
        collate_func : callable, optional
            a function that takes a list of samples and returns a batch and inherits from _PadCollate
        """

        super().__init__(
            dataset,
            collate_fn=collate_func(
                mask_residues=mask_residues,
                mask_whole_chains=mask_whole_chains,
                mask_frac=mask_frac,
                lower_limit=lower_limit,
                upper_limit=upper_limit,
                force_binding_sites_frac=force_binding_sites_frac,
                mask_all_cdrs=mask_all_cdrs,
            ),
            shuffle=shuffle_batches,
            *args,
            **kwargs,
        )

    @staticmethod
    def from_args(
        dataset_folder,
        features_folder="./data/tmp/",
        clustering_dict_path=None,
        max_length=None,
        rewrite=False,
        use_fraction=1,
        load_to_ram=False,
        debug=False,
        interpolate="none",
        node_features_type=None,
        entry_type="biounit",  # biounit, chain, pair
        classes_to_exclude=None,
        lower_limit=15,
        upper_limit=100,
        mask_residues=True,
        mask_whole_chains=False,
        mask_frac=None,
        force_binding_sites_frac=0,
        shuffle_clusters=True,
        shuffle_batches=True,
        mask_all_cdrs=False,
        classes_dict_path=None,
        *args,
        **kwargs,
    ) -> None:
        """
        Creates a `ProteinLoader` instance with a `ProteinDataset` from the given arguments

        Parameters
        ----------
        dataset_folder : str
            the path to the folder with proteinflow format input files (assumes that files are named {biounit_id}.pickle)
        features_folder : str
            the path to the folder where the ProteinMPNN features will be saved
        clustering_dict_path : str, optional
            path to the pickled clustering dictionary (keys are cluster ids, values are (biounit id, chain id) tuples)
        max_length : int, optional
            entries with total length of chains larger than `max_length` will be disregarded
        rewrite : bool, default False
            if `False`, existing feature files are not overwritten
        use_fraction : float, default 1
            the fraction of the clusters to use (first N in alphabetic order)
        load_to_ram : bool, default False
            if `True`, the data will be stored in RAM (use with caution! if RAM isn't big enough the machine might crash)
        debug : bool, default False
            only process 1000 files
        interpolate : {"none", "only_middle", "all"}
            `"none"` for no interpolation, `"only_middle"` for only linear interpolation in the middle, `"all"` for linear interpolation + ends generation
        node_features_type : {"dihedral", "sidechain_orientation", "chemical", "secondary_structure", "sidechain_coords", or combinations with "+"}, optional
            the type of node features, e.g. `"dihedral"` or `"sidechain_orientation+chemical"`
        entry_type : {"biounit", "chain", "pair"}
            the type of entries to generate (`"biounit"` for biounit-level, `"chain"` for chain-level, `"pair"` for chain-chain pairs)
        classes_to_exclude : list of str, optional
            a list of classes to exclude from the dataset (select from `"single_chains"`, `"heteromers"`, `"homomers"`)
        lower_limit : int, default 15
            the minimum number of residues to mask
        upper_limit : int, default 100
            the maximum number of residues to mask
        mask_frac : float, optional
            if given, the `lower_limit` and `upper_limit` are ignored and the number of residues to mask is `mask_frac` times the length of the chain
        mask_whole_chains : bool, default False
            if `True`, `upper_limit`, `force_binding_sites` and `lower_limit` are ignored and the whole chain is masked instead
        force_binding_sites_frac : float, default 0
            if > 0, in the fraction of cases where a chain from a polymer is sampled, the center of the masked region will be
            forced to be in a binding site
        shuffle_clusters : bool, default True
            if `True`, a new representative is randomly selected for each cluster at each epoch (if `clustering_dict_path` is given)
        shuffle_batches : bool, default True
            if `True`, the batches are shuffled at each epoch
        mask_all_cdrs : bool, default False
            if `True`, all CDRs are masked instead of just the sampled one
        classes_dict_path : str, optional
            path to the pickled classes dictionary
        """

        dataset = ProteinDataset(
            dataset_folder=dataset_folder,
            features_folder=features_folder,
            clustering_dict_path=clustering_dict_path,
            max_length=max_length,
            rewrite=rewrite,
            use_fraction=use_fraction,
            load_to_ram=load_to_ram,
            debug=debug,
            interpolate=interpolate,
            node_features_type=node_features_type,
            entry_type=entry_type,
            classes_to_exclude=classes_to_exclude,
            shuffle_clusters=shuffle_clusters,
            classes_dict_path=classes_dict_path,
        )
        return ProteinLoader(
            dataset=dataset,
            lower_limit=lower_limit,
            upper_limit=upper_limit,
            mask_residues=mask_residues,
            mask_whole_chains=mask_whole_chains,
            mask_frac=mask_frac,
            force_binding_sites_frac=force_binding_sites_frac,
            shuffle_batches=shuffle_batches,
            mask_all_cdrs=mask_all_cdrs,
            *args,
            **kwargs,
        )
