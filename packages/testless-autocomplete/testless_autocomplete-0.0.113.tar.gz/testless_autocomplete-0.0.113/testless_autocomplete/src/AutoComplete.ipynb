{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggest word that i am writing now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a list of common words and phrases\n",
    "common_words = [\"the\", \"and\", \"of\", \"to\", \"in\", \"a\", \"for\", \"is\", \"that\",\n",
    "\"with\", \"on\", \"at\", \"by\", \"this\", \"you\", \"not\", \"be\", \"are\", \"from\",\n",
    "\"or\", \"an\", \"but\", \"we\", \"can\", \"have\", \"as\", \"your\", \"all\", \"if\",\n",
    "\"out\", \"when\", \"up\", \"there\", \"use\", \"so\", \"no\", \"do\", \"what\", \"my\",\n",
    "\"which\", \"their\", \"about\", \"me\", \"will\", \"into\", \"like\", \"has\", \"them\",\n",
    "\"than\", \"just\", \"other\", \"then\", \"would\", \"some\", \"could\", \"its\",\n",
    "\"these\", \"two\", \"may\", \"many\", \"make\", \"most\", \"know\", \"see\", \"much\",\n",
    "\"need\", \"our\", \"before\", \"such\", \"because\", \"very\", \"any\", \"now\",\n",
    "\"over\", \"time\", \"only\", \"new\", \"years\", \"even\", \"year\", \"day\", \"people\",\n",
    "\"after\", \"first\", \"last\", \"way\", \"well\", \"where\", \"get\", \"go\", \"back\", \"good\",\n",
    "\"how\", \"down\", \"also\", \"two\", \"want\", \"between\", \"life\", \"work\", \"should\", \"never\",\n",
    "\"great\", \"ever\", \"find\", \"long\", \"give\", \"always\", \"right\", \"world\", \"same\", \"still\",\n",
    "\"think\", \"last\", \"high\", \"might\", \"end\", \"every\", \"while\", \"under\", \"such\", \"part\",\n",
    "\"small\", \"few\", \"place\", \"own\", \"head\", \"house\", \"hand\", \"eyes\", \"face\", \"room\",\n",
    "\"world\", \"water\", \"air\", \"earth\", \"fire\",\"click\" , \"enter\" , \"tap\" ]\n",
    "\n",
    "def suggest_completions(prefix):\n",
    "    completions = []\n",
    "    prefix = prefix.lower()\n",
    "    for word in common_words:\n",
    "        if word.startswith(prefix):\n",
    "            completions.append(word)\n",
    "    completions.sort(key=lambda x: common_words.count(x), reverse=True)\n",
    "    return completions[:1] # return the top 10 most common suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_completions(\"th\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggest next word from phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# Define a dictionary of common phrases that follow specific words\n",
    "phrases = {\n",
    "    \"I am\": [\"going to\", \"looking for\", \"thinking about\"],\n",
    "    \"How are\": [\"you\", \"things\", \"work\"],\n",
    "    \"Can you\": [\"help me\", \"give me\", \"tell me\"],\n",
    "    \"What is\": [\"the weather\", \"your name\", \"going on\"],\n",
    "    \"Where is\": [\"the bathroom\", \"the nearest store\", \"my phone\"],\n",
    "    \"I need\": [\"to go\", \"some help\", \"a break\"],\n",
    "    \"click\": [\"on the\", \"the button\", \"the link\"],\n",
    "}\n",
    "\n",
    "# Define a deque to keep track of the last few words typed\n",
    "# Define a deque to keep track of the last few words typed\n",
    "last_words = collections.deque(maxlen=3)\n",
    "\n",
    "def suggest_upcoming_words(current_text):\n",
    "    # Split the current text into individual words\n",
    "    words = current_text.split()\n",
    "    \n",
    "    # Add the last few words to the deque\n",
    "    for word in words[-3:]:\n",
    "        last_words.append(word)\n",
    "    \n",
    "    # Check if the last few words match a common phrase\n",
    "    for phrase, options in phrases.items():\n",
    "        if list(last_words)[-len(phrase.split()):] == phrase.split():\n",
    "            return options\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions for 'click ':\n",
      "- on the\n",
      "- the button\n",
      "- the link\n"
     ]
    }
   ],
   "source": [
    "# Call suggest_upcoming_words with an example text\n",
    "text = \"click \"\n",
    "suggestions = suggest_upcoming_words(text)\n",
    "\n",
    "# Print the suggestions\n",
    "print(\"Suggestions for '{}':\".format(text))\n",
    "for suggestion in suggestions:\n",
    "    print(\"- {}\".format(suggestion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggestion models \n",
    "# word_vectprs\n",
    "# bigram\n",
    "# trigram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying N-gram Model for auto-complete depending on our data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a Pandas DataFrame\n",
    "data = pd.read_csv('../text Analyzer/ner_testing.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the login button should be disabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the title of the page should be equals to 'Hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the email input should have a value of hello@m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you should see 2 tags of class tagClass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sould have 4 inputs of type text in the form</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                the login button should be disabled\n",
       "1  the title of the page should be equals to 'Hel...\n",
       "2  the email input should have a value of hello@m...\n",
       "3            you should see 2 tags of class tagClass\n",
       "4       sould have 4 inputs of type text in the form"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the text data\n",
    "# Define a function to preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # Remove any punctuation\n",
    "    text = ''.join(c for c in text if c.isalnum() or c.isspace())\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Split into individual words\n",
    "    words = text.split()\n",
    "    # Remove any stop words (optional)\n",
    "    # words = [w for w in words if w not in stop_words]\n",
    "    return words\n",
    "\n",
    "# drop Asserion, Action, Target, Value columns\n",
    "data = data.drop(['assertion', 'action', 'target', 'value'], axis=1)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the login button should be disabled</td>\n",
       "      <td>[the, login, button, should, be, disabled]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the title of the page should be equals to 'Hel...</td>\n",
       "      <td>[the, title, of, the, page, should, be, equals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the email input should have a value of hello@m...</td>\n",
       "      <td>[the, email, input, should, have, a, value, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you should see 2 tags of class tagClass</td>\n",
       "      <td>[you, should, see, 2, tags, of, class, tagclass]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sould have 4 inputs of type text in the form</td>\n",
       "      <td>[sould, have, 4, inputs, of, type, text, in, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                the login button should be disabled   \n",
       "1  the title of the page should be equals to 'Hel...   \n",
       "2  the email input should have a value of hello@m...   \n",
       "3            you should see 2 tags of class tagClass   \n",
       "4       sould have 4 inputs of type text in the form   \n",
       "\n",
       "                                               words  \n",
       "0         [the, login, button, should, be, disabled]  \n",
       "1  [the, title, of, the, page, should, be, equals...  \n",
       "2  [the, email, input, should, have, a, value, of...  \n",
       "3   [you, should, see, 2, tags, of, class, tagclass]  \n",
       "4  [sould, have, 4, inputs, of, type, text, in, t...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['words'] = data['text'].apply(preprocess_text)\n",
    "data.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(data, n=2):\n",
    "    # Initialize a defaultdict to store the n-grams\n",
    "    ngrams = defaultdict(list)\n",
    "    \n",
    "    # Loop through each row in the data\n",
    "    for i, row in data.iterrows():\n",
    "        # Get the list of words in the row\n",
    "        words = row['words']\n",
    "        \n",
    "        # Loop through each 2-gram in the row and add it to the defaultdict \n",
    "        # Build the 2-gram model by adding word and its next word to the dictionary\n",
    "        for j in range(len(words) - n + 1):\n",
    "            ngram = ' '.join(words[j:j+n-1])\n",
    "            next_word = words[j+n-1]\n",
    "            ngrams[ngram].append(next_word)\n",
    "    \n",
    "    return ngrams\n",
    "\n",
    "# Build the 2-gram model\n",
    "ngrams = build_ngram_model(data, n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"ngram.csv\", 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['ngram', 'next_word'])\n",
    "        for ngram, next_words in ngrams.items():\n",
    "            writer.writerow([ngram,  sorted(set(next_words), key=next_words.count, reverse=True)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggest word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate autocomplete suggestions\n",
    "def suggest_words(text, ngrams, n=2):\n",
    "    # Preprocess the text\n",
    "    words = preprocess_text(text)\n",
    "    \n",
    "    # Get the most common next words for the 2-gram\n",
    "    ngram = ' '.join(words[-n+1:]) if len(words) >= n else ''\n",
    "    # print(ngram)\n",
    "    if ngram in ngrams:\n",
    "        next_words = ngrams[ngram]\n",
    "        suggestions = sorted(set(next_words), key=next_words.count, reverse=True)\n",
    "    else:\n",
    "        suggestions = []\n",
    "    \n",
    "    return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'should',\n",
       " 'have',\n",
       " 'is',\n",
       " 'that',\n",
       " 'will',\n",
       " 'sort',\n",
       " 'submit',\n",
       " 'for',\n",
       " 'in',\n",
       " 'login']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_words(\"click on button\", ngrams, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words:\n",
      " ['to', 'should', 'have', 'is', 'that', 'will', 'sort', 'submit', 'for', 'in', 'login']\n"
     ]
    }
   ],
   "source": [
    "words = preprocess_text(\"click on button\")\n",
    "data = pd.read_csv('ngram.csv')\n",
    "data.set_index('ngram', inplace=True)\n",
    "print(\"words:\\n\" , data.loc[\"button\"]['next_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
